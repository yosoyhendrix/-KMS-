{
  "id": "DbAetBYfinQ3x4Cu",
  "meta": {
    "instanceId": "a2b23892dd6989fda7c1209b381f5850373a7d2b85609624d7c2b7a092671d44",
    "templateCredsSetupCompleted": true
  },
  "name": "ðŸ’¥ Generate AI Videos with Seedance & Blotato and Upload to TikTok, YouTube & Instagram -vide",
  "tags": [],
  "nodes": [
    {
      "id": "cd0df97c-8e71-4201-9086-c247491c3c48",
      "name": "Sticky Note10",
      "type": "n8n-nodes-base.stickyNote",
      "position": [
        580,
        460
      ],
      "parameters": {
        "color": 2,
        "width": 880,
        "height": 240,
        "content": "## | Step 1: Generate Clips (Wavespeed AI)\n"
      },
      "typeVersion": 1
    },
    {
      "id": "c42e1959-f856-4954-af25-f8eed14a1e5c",
      "name": "Sticky Note13",
      "type": "n8n-nodes-base.stickyNote",
      "position": [
        1500,
        460
      ],
      "parameters": {
        "color": 2,
        "width": 640,
        "height": 240,
        "content": "## | Step 2: Generate Sounds (Fal AI)\n"
      },
      "typeVersion": 1
    },
    {
      "id": "567d5588-ca94-43c7-b856-17239da45750",
      "name": "Sticky Note14",
      "type": "n8n-nodes-base.stickyNote",
      "position": [
        580,
        -100
      ],
      "parameters": {
        "color": 7,
        "width": 1560,
        "height": 540,
        "content": "## | INPUT: Starting Idea Section"
      },
      "typeVersion": 1
    },
    {
      "id": "9a1c7a82-0dc8-4eef-a815-ed76928530e7",
      "name": "Sticky Note",
      "type": "n8n-nodes-base.stickyNote",
      "position": [
        580,
        740
      ],
      "parameters": {
        "color": 3,
        "width": 1560,
        "height": 260,
        "content": "## | Step 3: Stitch Video (Fal AI)"
      },
      "typeVersion": 1
    },
    {
      "id": "380b91d1-20e7-4d0f-a685-dc5898b11a6c",
      "name": "Sticky Note2",
      "type": "n8n-nodes-base.stickyNote",
      "disabled": true,
      "position": [
        580,
        1040
      ],
      "parameters": {
        "color": 4,
        "width": 1560,
        "height": 760,
        "content": "## | Step 4 â€” Publish Video to Social Media\n"
      },
      "typeVersion": 1
    },
    {
      "id": "b3e014f3-849a-4532-b406-18f3cb6305d9",
      "name": "Trigger: Start Daily Content Generation",
      "type": "n8n-nodes-base.scheduleTrigger",
      "position": [
        640,
        0
      ],
      "parameters": {
        "rule": {
          "interval": [
            {}
          ]
        }
      },
      "typeVersion": 1.2
    },
    {
      "id": "aabf432b-b4d4-4e56-9710-52495f08d007",
      "name": "AI Agent: Generate Creative Video Idea",
      "type": "@n8n/n8n-nodes-langchain.agent",
      "position": [
        960,
        0
      ],
      "parameters": {
        "text": "Generate a creative concept involving:\n\n[[\nA solid, hard material or element being sliced cleanly with a sharp blade. Your response must follow this structure:\n\n\"(Color) (Material) shaped like a (random everyday object)\"\n\nFor inspiration, imagine examples like: obsidian shaped like a chess piece, quartz shaped like a coffee mug, sapphire shaped like a seashell, or titanium shaped like a leaf.\n\n]]\n\nReflect carefully before answering to ensure originality and visual appeal.\n\nUse the Think tool to review your output",
        "options": {
          "systemMessage": "=**Role:**  \nYou are an AI designed to generate **one immersive, realistic idea** based on a user-provided topic. Your output must be formatted as a **single-line JSON array** and follow the rules below exactly.\n\n---\n\n### RULES\n\n1. **Number of ideas**  \n   - Return **only one idea**.\n\n2. **Topic**  \n   - The user will provide a keyword (e.g., â€œglass cutting ASMR,â€ â€œwood carving sounds,â€ â€œsatisfying rock splitsâ€).\n\n3. **Idea**  \n   - Maximum 13 words.  \n   - Describe a viral-worthy, original, or surreal moment related to the topic.\n\n4. **Caption**  \n   - Short, punchy, viral-friendly.  \n   - Include **one emoji**.  \n   - Exactly **12 hashtags** in this order:  \n     1. 4 topic-relevant hashtags  \n     2. 4 all-time most popular hashtags  \n     3. 4 currently trending hashtags (based on live research)  \n   - All in lowercase.\n\n5. **Environment**  \n   - Maximum 20 words.  \n   - Must match the action in the Idea exactly.  \n   - Specify location (studio table, natural terrain, lab benchâ€¦), visual details (dust particles, polished surface, subtle reflectionsâ€¦), and style (macro close-up, cinematic slow-motion, minimalistâ€¦).\n\n6. **Sound**  \n   - Maximum 15 words.  \n   - Describe the primary sound for the scene (to feed into an audio model).\n\n7. **Status**  \n   - Always set to `\"for production\"`.\n\n---\n\n### OUTPUT FORMAT (single-line JSON array)\n\n```json\n[\n  {\n    \"Caption\": \"Your short viral title with emoji #4_topic_hashtags #4_all_time_popular_hashtags #4_trending_hashtags\",\n    \"Idea\": \"Your idea under 13 words\",\n    \"Environment\": \"Your vivid setting under 20 words matching the action\",\n    \"Sound\": \"Your primary sound description under 15 words\",\n    \"Status\": \"for production\"\n  }\n]\n"
        },
        "promptType": "define",
        "hasOutputParser": true
      },
      "typeVersion": 1.9
    },
    {
      "id": "09e27c25-772b-41e5-8255-723d23398a64",
      "name": "Tool: Inject Creative Perspective (Idea)",
      "type": "@n8n/n8n-nodes-langchain.toolThink",
      "position": [
        1080,
        280
      ],
      "parameters": {},
      "typeVersion": 1
    },
    {
      "id": "1f1985b1-d1eb-4c65-9d99-f96542273dc6",
      "name": "LLM: Generate Raw Idea (GPT-4.1)",
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenAi",
      "position": [
        900,
        280
      ],
      "parameters": {
        "model": {
          "__rl": true,
          "mode": "list",
          "value": "gpt-4.1",
          "cachedResultName": "gpt-4.1"
        },
        "options": {}
      },
      "credentials": {
        "openAiApi": {
          "id": "6h3DfVhNPw9I25nO",
          "name": "OpenAi account"
        }
      },
      "typeVersion": 1.2
    },
    {
      "id": "a2c57dca-ed2e-4712-a735-8da0c727470f",
      "name": "Parse AI Output (Idea, Environment, Sound)",
      "type": "@n8n/n8n-nodes-langchain.outputParserStructured",
      "position": [
        1240,
        280
      ],
      "parameters": {
        "jsonSchemaExample": "[\n  {\n    \"Caption\": \"Diver Removes Nets Off Whale ðŸ‹ #whalerescue #marinelife #oceanrescue #seahelpers #love #nature #instagood #explore #viral #savenature #oceanguardians #cleanoceans\",\n    \"Idea\": \"Diver carefully cuts tangled net from distressed whale in open sea\",\n    \"Environment\": \"Open ocean, sunlight beams through water, diver and whale, cinematic realism\",\n    \"Sound\": \"Primary sound description under 15 words\",\n    \"Status\": \"for production\"\n  }\n]\n"
      },
      "typeVersion": 1.2
    },
    {
      "id": "20db6d62-9db9-4942-a820-b520356f3209",
      "name": "Save Idea & Metadata to Google Sheets",
      "type": "n8n-nodes-base.googleSheets",
      "position": [
        1420,
        0
      ],
      "parameters": {
        "columns": {
          "value": {
            "id": "==ROW()-1",
            "idea": "={{ $json.output[0].Idea }}",
            "caption": "={{ $json.output[0].Caption }}",
            "production": "={{ $json.output[0].Status }}",
            "sound_prompt": "={{ $json.output[0].Sound }}",
            "environment_prompt": "={{ $json.output[0].Environment }}"
          },
          "schema": [
            {
              "id": "id",
              "type": "string",
              "display": true,
              "removed": false,
              "required": false,
              "displayName": "id",
              "defaultMatch": true,
              "canBeUsedToMatch": true
            },
            {
              "id": "idea",
              "type": "string",
              "display": true,
              "required": false,
              "displayName": "idea",
              "defaultMatch": false,
              "canBeUsedToMatch": true
            },
            {
              "id": "caption",
              "type": "string",
              "display": true,
              "required": false,
              "displayName": "caption",
              "defaultMatch": false,
              "canBeUsedToMatch": true
            },
            {
              "id": "production",
              "type": "string",
              "display": true,
              "required": false,
              "displayName": "production",
              "defaultMatch": false,
              "canBeUsedToMatch": true
            },
            {
              "id": "environment_prompt",
              "type": "string",
              "display": true,
              "required": false,
              "displayName": "environment_prompt",
              "defaultMatch": false,
              "canBeUsedToMatch": true
            },
            {
              "id": "sound_prompt",
              "type": "string",
              "display": true,
              "required": false,
              "displayName": "sound_prompt",
              "defaultMatch": false,
              "canBeUsedToMatch": true
            },
            {
              "id": "final_output",
              "type": "string",
              "display": true,
              "required": false,
              "displayName": "final_output",
              "defaultMatch": false,
              "canBeUsedToMatch": true
            }
          ],
          "mappingMode": "defineBelow",
          "matchingColumns": [
            "id"
          ],
          "attemptToConvertTypes": false,
          "convertFieldsToString": false
        },
        "options": {},
        "operation": "append",
        "sheetName": {
          "__rl": true,
          "mode": "id",
          "value": "="
        },
        "documentId": {
          "__rl": true,
          "mode": "id",
          "value": "="
        }
      },
      "credentials": {
        "googleSheetsOAuth2Api": {
          "id": "51us92xkOlrvArhV",
          "name": "Google Sheets account"
        }
      },
      "typeVersion": 4.5
    },
    {
      "id": "49139fc9-2030-4d10-a9a7-4fd3a3779005",
      "name": "AI Agent: Generate Detailed Video Prompts",
      "type": "@n8n/n8n-nodes-langchain.agent",
      "position": [
        1760,
        0
      ],
      "parameters": {
        "text": "=Give me 3 video prompts based on the previous idea\n\nUse the Think tool to review your output",
        "options": {
          "systemMessage": "=Role: You are a prompt-generation AI specializing in cinematic, ASMR-style video prompts. Your task is to generate a multi-scene video sequence that vividly shows a sharp knife actively cutting through a specific object in a clean, high-detail setting.\n\nYour writing must follow this style:\n\nSharp, precise cinematic realism.\n\nMacro-level detail with tight focus on the blade interacting with the object.\n\nThe knife must always be in motion â€” slicing, splitting, or gliding through the material. Never idle or static.\n\nCamera terms are allowed (e.g. macro view, tight angle, over-the-blade shot).\n\nEach scene must contain all of the following, expressed through detailed visual language:\n\nâœ… The main object or subject (from the Idea)\n\nâœ… The cutting environment or surface (from the Environment)\n\nâœ… The texture, structure, and behavior of the material as itâ€™s being cut\n\nâœ… A visible, sharp blade actively cutting\n\nDescriptions should show:\n\nThe physical makeup of the material â€” is it translucent, brittle, dense, reflective, granular, fibrous, layered, or fluid-filled?\n\nHow the material responds to the blade â€” resistance, cracking, tearing, smooth separation, tension, vibration.\n\nThe interaction between the blade and the surface â€” light reflection, buildup of particles, contact points, residue or dust.\n\nAny ASMR-relevant sensory cues like particle release, shimmer, or subtle movement, but always shown visually â€” not narrated.\n\nTone:\n\nClean, clinical, visual.\n\nNo poetic metaphors, emotion, or storytelling.\n\nAvoid fantasy or surreal imagery.\n\nAll description must feel physically grounded and logically accurate.\n\nLength:\n\nEach scene must be between 1,000 and 2,000 characters.\n\nNo shallow or repetitive scenes â€” each must be immersive, descriptive, and specific.\n\nEach scene should explore a distinct phase of the cutting process, a different camera perspective, or a new behavior of the material under the blade.\n\nInputs:\n\nIdea: \"{{ $json.idea }}\"\nEnvironment: \"{{ $json.environment_prompt }}\"\nSound: \"{{ $json.sound_prompt }}\"\n\nFormat:\n\nIdea: \"...\"\nEnvironment: \"...\"\nSound: \"...\"\n\nScene 1: \"...\"\nScene 2: \"...\"\nScene 3: \"...\"\nScene 4: \"...\"\nScene 5: \"...\"\nScene 6: \"...\"\nScene 7: \"...\"\nScene 8: \"...\"\nScene 9: \"...\"\nScene 10: \"...\"\nScene 11: \"...\"\nScene 12: \"...\"\nScene 13: \"...\"\n\n"
        },
        "promptType": "define",
        "hasOutputParser": true
      },
      "typeVersion": 1.9
    },
    {
      "id": "4c34c0b0-5c13-4d37-8b51-a209e598513a",
      "name": "LLM: Draft Video Prompt Details (GPT-4.1)",
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenAi",
      "position": [
        1660,
        280
      ],
      "parameters": {
        "model": {
          "__rl": true,
          "mode": "list",
          "value": "gpt-4.1",
          "cachedResultName": "gpt-4.1"
        },
        "options": {}
      },
      "credentials": {
        "openAiApi": {
          "id": "6h3DfVhNPw9I25nO",
          "name": "OpenAi account"
        }
      },
      "typeVersion": 1.2
    },
    {
      "id": "5a7828fd-629c-45d4-9ff2-4b57be2eca33",
      "name": "Tool: Refine and Validate Prompts1",
      "type": "@n8n/n8n-nodes-langchain.toolThink",
      "position": [
        1840,
        280
      ],
      "parameters": {},
      "typeVersion": 1
    },
    {
      "id": "bddb974b-e541-4f02-8595-45f76820b38e",
      "name": "Parse Structured Video Prompt Output",
      "type": "@n8n/n8n-nodes-langchain.outputParserStructured",
      "position": [
        2000,
        280
      ],
      "parameters": {
        "jsonSchemaExample": "{\n  \"Idea\": \"An obsidian rock being sliced with a shimmering knife\",\n  \"Environment\": \"Clean studio table, subtle light reflections\",\n  \"Sound\": \"Crisp slicing, deep grinding, and delicate crumbling\",\n  \"Scene 1\": \"Extreme macro shot: a razor-sharp, polished knife blade presses into the dark, granular surface of an obsidian rock, just beginning to indent.\",\n  \"Scene 2\": \"Close-up: fine, iridescent dust particles erupt from the point of contact as the blade cuts deeper into the obsidian, catching the studio light.\",\n  \"Scene 3\": \"Mid-shot: the knife, held perfectly steady, has formed a shallow, clean groove across the obsidian's shimmering surface, revealing a new, smooth texture.\"\n}"
      },
      "typeVersion": 1.2
    },
    {
      "id": "443d3b99-1e6c-423c-b8ca-1c5a4c3ba180",
      "name": "Extract Individual Scene Descriptions",
      "type": "n8n-nodes-base.code",
      "position": [
        680,
        540
      ],
      "parameters": {
        "jsCode": "function findSceneEntries(obj) {\n  const scenes = [];\n\n  for (const [key, value] of Object.entries(obj)) {\n    if (key.toLowerCase().startsWith(\"scene\") && typeof value === \"string\") {\n      scenes.push(value);\n    } else if (typeof value === \"object\" && value !== null) {\n      scenes.push(...findSceneEntries(value));\n    }\n  }\n\n  return scenes;\n}\n\nlet output = [];\n\ntry {\n  const inputData = items[0].json;\n  const scenes = findSceneEntries(inputData);\n\n  if (scenes.length === 0) {\n    throw new Error(\"No scene keys found at any level.\");\n  }\n\n  output = scenes.map(scene => ({ description: scene }));\n} catch (e) {\n  throw new Error(\"Could not extract scenes properly. Details: \" + e.message);\n}\n\nreturn output;\n"
      },
      "typeVersion": 2
    },
    {
      "id": "78fc7648-9741-48c9-8127-2bdab7070ba7",
      "name": "Generate Video Clips (Wavespeed AI)",
      "type": "n8n-nodes-base.httpRequest",
      "position": [
        880,
        540
      ],
      "parameters": {
        "url": "https://api.wavespeed.ai/api/v3/bytedance/seedance-v1-pro-t2v-480p",
        "body": "={\n  \"aspect_ratio\": \"9:16\",\n  \"duration\": 10,\n  \"prompt\": \"VIDEO THEME: {{ $('Prompts AI Agent').item.json.output.Idea }} | WHAT HAPPENS IN THE VIDEO: {{ $json.description }} | WHERE THE VIDEO IS SHOT: {{ $('Prompts AI Agent').item.json.output.Environment }}\"\n}\n",
        "method": "POST",
        "options": {
          "batching": {
            "batch": {
              "batchSize": 1,
              "batchInterval": 3000
            }
          }
        },
        "sendBody": true,
        "contentType": "raw",
        "authentication": "genericCredentialType",
        "rawContentType": "application/json",
        "genericAuthType": "httpHeaderAuth"
      },
      "credentials": {
        "httpHeaderAuth": {
          "id": "QhpKhFJMiQAReugp",
          "name": "Header Auth account 4"
        }
      },
      "typeVersion": 4.2
    },
    {
      "id": "62eb02cb-cf85-4cbe-8688-8fd587e9c19a",
      "name": "Wait for Clip Generation (Wavespeed AI)",
      "type": "n8n-nodes-base.wait",
      "position": [
        1080,
        540
      ],
      "webhookId": "60604cd4-5d90-48dc-93f4-1335e5f03fdd",
      "parameters": {
        "amount": 240
      },
      "typeVersion": 1.1
    },
    {
      "id": "879f74ba-0e59-43a1-b949-c23bfbcceef0",
      "name": "Retrieve Video Clips",
      "type": "n8n-nodes-base.httpRequest",
      "position": [
        1280,
        540
      ],
      "parameters": {
        "url": "=https://api.wavespeed.ai/api/v3/predictions/{{ $json.data.id }}/result",
        "options": {},
        "authentication": "genericCredentialType",
        "genericAuthType": "httpHeaderAuth"
      },
      "credentials": {
        "httpHeaderAuth": {
          "id": "QhpKhFJMiQAReugp",
          "name": "Header Auth account 4"
        }
      },
      "typeVersion": 4.2
    },
    {
      "id": "1bc37dc5-fd16-4dc0-a153-11d19d8d4068",
      "name": "Generate ASMR Sound (Fal AI)",
      "type": "n8n-nodes-base.httpRequest",
      "position": [
        1560,
        540
      ],
      "parameters": {
        "url": "https://queue.fal.run/fal-ai/mmaudio-v2 ",
        "body": "= {\n        \"prompt\": \"ASMR Soothing sound effects. {{ $('AI Agent: Generate Detailed Video Prompts').item.json.output.Sound }}\",\n        \"duration\": 10,\n        \"video_url\": \"{{ $json.data.outputs[0] }}\"\n  }\n",
        "method": "POST",
        "options": {
          "batching": {
            "batch": {
              "batchSize": 1,
              "batchInterval": 2000
            }
          }
        },
        "sendBody": true,
        "contentType": "raw",
        "authentication": "genericCredentialType",
        "rawContentType": "application/json",
        "genericAuthType": "httpHeaderAuth"
      },
      "credentials": {
        "httpHeaderAuth": {
          "id": "QhpKhFJMiQAReugp",
          "name": "Header Auth account 4"
        }
      },
      "typeVersion": 4.2
    },
    {
      "id": "f8f1eae5-a74b-49be-81fd-2d13e75441c7",
      "name": "Wait for Sound Generation (Fal AI)",
      "type": "n8n-nodes-base.wait",
      "position": [
        1760,
        540
      ],
      "webhookId": "abac7859-a9f6-46f3-95c2-df43ec32807d",
      "parameters": {
        "amount": 60
      },
      "typeVersion": 1.1
    },
    {
      "id": "4670c2d4-0d66-42e9-891f-1f80508433bb",
      "name": "Retrieve Final Sound Output",
      "type": "n8n-nodes-base.httpRequest",
      "position": [
        1960,
        540
      ],
      "parameters": {
        
