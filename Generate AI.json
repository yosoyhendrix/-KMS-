{
  "id": "DbAetBYfinQ3x4Cu",
  "meta": {
    "instanceId": "a2b23892dd6989fda7c1209b381f5850373a7d2b85609624d7c2b7a092671d44",
    "templateCredsSetupCompleted": true
  },
  "name": "üí• Generate AI Videos with Seedance & Blotato and Upload to TikTok, YouTube & Instagram -vide",
  "tags": [],
  "nodes": [
    {
      "id": "cd0df97c-8e71-4201-9086-c247491c3c48",
      "name": "Sticky Note10",
      "type": "n8n-nodes-base.stickyNote",
      "position": [
        580,
        460
      ],
      "parameters": {
        "color": 2,
        "width": 880,
        "height": 240,
        "content": "## | Step 1: Generate Clips (Wavespeed AI)\n"
      },
      "typeVersion": 1
    },
    {
      "id": "c42e1959-f856-4954-af25-f8eed14a1e5c",
      "name": "Sticky Note13",
      "type": "n8n-nodes-base.stickyNote",
      "position": [
        1500,
        460
      ],
      "parameters": {
        "color": 2,
        "width": 640,
        "height": 240,
        "content": "## | Step 2: Generate Sounds (Fal AI)\n"
      },
      "typeVersion": 1
    },
    {
      "id": "567d5588-ca94-43c7-b856-17239da45750",
      "name": "Sticky Note14",
      "type": "n8n-nodes-base.stickyNote",
      "position": [
        580,
        -100
      ],
      "parameters": {
        "color": 7,
        "width": 1560,
        "height": 540,
        "content": "## | INPUT: Starting Idea Section"
      },
      "typeVersion": 1
    },
    {
      "id": "9a1c7a82-0dc8-4eef-a815-ed76928530e7",
      "name": "Sticky Note",
      "type": "n8n-nodes-base.stickyNote",
      "position": [
        580,
        740
      ],
      "parameters": {
        "color": 3,
        "width": 1560,
        "height": 260,
        "content": "## | Step 3: Stitch Video (Fal AI)"
      },
      "typeVersion": 1
    },
    {
      "id": "380b91d1-20e7-4d0f-a685-dc5898b11a6c",
      "name": "Sticky Note2",
      "type": "n8n-nodes-base.stickyNote",
      "disabled": true,
      "position": [
        580,
        1040
      ],
      "parameters": {
        "color": 4,
        "width": 1560,
        "height": 760,
        "content": "## | Step 4 ‚Äî Publish Video to Social Media\n"
      },
      "typeVersion": 1
    },
    {
      "id": "b3e014f3-849a-4532-b406-18f3cb6305d9",
      "name": "Trigger: Start Daily Content Generation",
      "type": "n8n-nodes-base.scheduleTrigger",
      "position": [
        640,
        0
      ],
      "parameters": {
        "rule": {
          "interval": [
            {}
          ]
        }
      },
      "typeVersion": 1.2
    },
    {
      "id": "aabf432b-b4d4-4e56-9710-52495f08d007",
      "name": "AI Agent: Generate Creative Video Idea",
      "type": "@n8n/n8n-nodes-langchain.agent",
      "position": [
        960,
        0
      ],
      "parameters": {
        "text": "Generate a creative concept involving:\n\n[[\nA solid, hard material or element being sliced cleanly with a sharp blade. Your response must follow this structure:\n\n\"(Color) (Material) shaped like a (random everyday object)\"\n\nFor inspiration, imagine examples like: obsidian shaped like a chess piece, quartz shaped like a coffee mug, sapphire shaped like a seashell, or titanium shaped like a leaf.\n\n]]\n\nReflect carefully before answering to ensure originality and visual appeal.\n\nUse the Think tool to review your output",
        "options": {
          "systemMessage": "=**Role:**  \nYou are an AI designed to generate **one immersive, realistic idea** based on a user-provided topic. Your output must be formatted as a **single-line JSON array** and follow the rules below exactly.\n\n---\n\n### RULES\n\n1. **Number of ideas**  \n   - Return **only one idea**.\n\n2. **Topic**  \n   - The user will provide a keyword (e.g., ‚Äúglass cutting ASMR,‚Äù ‚Äúwood carving sounds,‚Äù ‚Äúsatisfying rock splits‚Äù).\n\n3. **Idea**  \n   - Maximum 13 words.  \n   - Describe a viral-worthy, original, or surreal moment related to the topic.\n\n4. **Caption**  \n   - Short, punchy, viral-friendly.  \n   - Include **one emoji**.  \n   - Exactly **12 hashtags** in this order:  \n     1. 4 topic-relevant hashtags  \n     2. 4 all-time most popular hashtags  \n     3. 4 currently trending hashtags (based on live research)  \n   - All in lowercase.\n\n5. **Environment**  \n   - Maximum 20 words.  \n   - Must match the action in the Idea exactly.  \n   - Specify location (studio table, natural terrain, lab bench‚Ä¶), visual details (dust particles, polished surface, subtle reflections‚Ä¶), and style (macro close-up, cinematic slow-motion, minimalist‚Ä¶).\n\n6. **Sound**  \n   - Maximum 15 words.  \n   - Describe the primary sound for the scene (to feed into an audio model).\n\n7. **Status**  \n   - Always set to `\"for production\"`.\n\n---\n\n### OUTPUT FORMAT (single-line JSON array)\n\n```json\n[\n  {\n    \"Caption\": \"Your short viral title with emoji #4_topic_hashtags #4_all_time_popular_hashtags #4_trending_hashtags\",\n    \"Idea\": \"Your idea under 13 words\",\n    \"Environment\": \"Your vivid setting under 20 words matching the action\",\n    \"Sound\": \"Your primary sound description under 15 words\",\n    \"Status\": \"for production\"\n  }\n]\n"
        },
        "promptType": "define",
        "hasOutputParser": true
      },
      "typeVersion": 1.9
    },
    {
      "id": "09e27c25-772b-41e5-8255-723d23398a64",
      "name": "Tool: Inject Creative Perspective (Idea)",
      "type": "@n8n/n8n-nodes-langchain.toolThink",
      "position": [
        1080,
        280
      ],
      "parameters": {},
      "typeVersion": 1
    },
    {
      "id": "1f1985b1-d1eb-4c65-9d99-f96542273dc6",
      "name": "LLM: Generate Raw Idea (GPT-4.1)",
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenAi",
      "position": [
        900,
        280
      ],
      "parameters": {
        "model": {
          "__rl": true,
          "mode": "list",
          "value": "gpt-4.1",
          "cachedResultName": "gpt-4.1"
        },
        "options": {}
      },
      "credentials": {
        "openAiApi": {
          "id": "6h3DfVhNPw9I25nO",
          "name": "OpenAi account"
        }
      },
      "typeVersion": 1.2
    },
    {
      "id": "a2c57dca-ed2e-4712-a735-8da0c727470f",
      "name": "Parse AI Output (Idea, Environment, Sound)",
      "type": "@n8n/n8n-nodes-langchain.outputParserStructured",
      "position": [
        1240,
        280
      ],
      "parameters": {
        "jsonSchemaExample": "[\n  {\n    \"Caption\": \"Diver Removes Nets Off Whale üêã #whalerescue #marinelife #oceanrescue #seahelpers #love #nature #instagood #explore #viral #savenature #oceanguardians #cleanoceans\",\n    \"Idea\": \"Diver carefully cuts tangled net from distressed whale in open sea\",\n    \"Environment\": \"Open ocean, sunlight beams through water, diver and whale, cinematic realism\",\n    \"Sound\": \"Primary sound description under 15 words\",\n    \"Status\": \"for production\"\n  }\n]\n"
      },
      "typeVersion": 1.2
    },
    {
      "id": "20db6d62-9db9-4942-a820-b520356f3209",
      "name": "Save Idea & Metadata to Google Sheets",
      "type": "n8n-nodes-base.googleSheets",
      "position": [
        1420,
        0
      ],
      "parameters": {
        "columns": {
          "value": {
            "id": "==ROW()-1",
            "idea": "={{ $json.output[0].Idea }}",
            "caption": "={{ $json.output[0].Caption }}",
            "production": "={{ $json.output[0].Status }}",
            "sound_prompt": "={{ $json.output[0].Sound }}",
            "environment_prompt": "={{ $json.output[0].Environment }}"
          },
          "schema": [
            {
              "id": "id",
              "type": "string",
              "display": true,
              "removed": false,
              "required": false,
              "displayName": "id",
              "defaultMatch": true,
              "canBeUsedToMatch": true
            },
            {
              "id": "idea",
              "type": "string",
              "display": true,
              "required": false,
              "displayName": "idea",
              "defaultMatch": false,
              "canBeUsedToMatch": true
            },
            {
              "id": "caption",
              "type": "string",
              "display": true,
              "required": false,
              "displayName": "caption",
              "defaultMatch": false,
              "canBeUsedToMatch": true
            },
            {
              "id": "production",
              "type": "string",
              "display": true,
              "required": false,
              "displayName": "production",
              "defaultMatch": false,
              "canBeUsedToMatch": true
            },
            {
              "id": "environment_prompt",
              "type": "string",
              "display": true,
              "required": false,
              "displayName": "environment_prompt",
              "defaultMatch": false,
              "canBeUsedToMatch": true
            },
            {
              "id": "sound_prompt",
              "type": "string",
              "display": true,
              "required": false,
              "displayName": "sound_prompt",
              "defaultMatch": false,
              "canBeUsedToMatch": true
            },
            {
              "id": "final_output",
              "type": "string",
              "display": true,
              "required": false,
              "displayName": "final_output",
              "defaultMatch": false,
              "canBeUsedToMatch": true
            }
          ],
          "mappingMode": "defineBelow",
          "matchingColumns": [
            "id"
          ],
          "attemptToConvertTypes": false,
          "convertFieldsToString": false
        },
        "options": {},
        "operation": "append",
        "sheetName": {
          "__rl": true,
          "mode": "id",
          "value": "="
        },
        "documentId": {
          "__rl": true,
          "mode": "id",
          "value": "="
        }
      },
      "credentials": {
        "googleSheetsOAuth2Api": {
          "id": "51us92xkOlrvArhV",
          "name": "Google Sheets account"
        }
      },
      "typeVersion": 4.5
    },
    {
      "id": "49139fc9-2030-4d10-a9a7-4fd3a3779005",
      "name": "AI Agent: Generate Detailed Video Prompts",
      "type": "@n8n/n8n-nodes-langchain.agent",
      "position": [
        1760,
        0
      ],
      "parameters": {
        "text": "=Give me 3 video prompts based on the previous idea\n\nUse the Think tool to review your output",
        "options": {
          "systemMessage": "=Role: You are a prompt-generation AI specializing in cinematic, ASMR-style video prompts. Your task is to generate a multi-scene video sequence that vividly shows a sharp knife actively cutting through a specific object in a clean, high-detail setting.\n\nYour writing must follow this style:\n\nSharp, precise cinematic realism.\n\nMacro-level detail with tight focus on the blade interacting with the object.\n\nThe knife must always be in motion ‚Äî slicing, splitting, or gliding through the material. Never idle or static.\n\nCamera terms are allowed (e.g. macro view, tight angle, over-the-blade shot).\n\nEach scene must contain all of the following, expressed through detailed visual language:\n\n‚úÖ The main object or subject (from the Idea)\n\n‚úÖ The cutting environment or surface (from the Environment)\n\n‚úÖ The texture, structure, and behavior of the material as it‚Äôs being cut\n\n‚úÖ A visible, sharp blade actively cutting\n\nDescriptions should show:\n\nThe physical makeup of the material ‚Äî is it translucent, brittle, dense, reflective, granular, fibrous, layered, or fluid-filled?\n\nHow the material responds to the blade ‚Äî resistance, cracking, tearing, smooth separation, tension, vibration.\n\nThe interaction between the blade and the surface ‚Äî light reflection, buildup of particles, contact points, residue or dust.\n\nAny ASMR-relevant sensory cues like particle release, shimmer, or subtle movement, but always shown visually ‚Äî not narrated.\n\nTone:\n\nClean, clinical, visual.\n\nNo poetic metaphors, emotion, or storytelling.\n\nAvoid fantasy or surreal imagery.\n\nAll description must feel physically grounded and logically accurate.\n\nLength:\n\nEach scene must be between 1,000 and 2,000 characters.\n\nNo shallow or repetitive scenes ‚Äî each must be immersive, descriptive, and specific.\n\nEach scene should explore a distinct phase of the cutting process, a different camera perspective, or a new behavior of the material under the blade.\n\nInputs:\n\nIdea: \"{{ $json.idea }}\"\nEnvironment: \"{{ $json.environment_prompt }}\"\nSound: \"{{ $json.sound_prompt }}\"\n\nFormat:\n\nIdea: \"...\"\nEnvironment: \"...\"\nSound: \"...\"\n\nScene 1: \"...\"\nScene 2: \"...\"\nScene 3: \"...\"\nScene 4: \"...\"\nScene 5: \"...\"\nScene 6: \"...\"\nScene 7: \"...\"\nScene 8: \"...\"\nScene 9: \"...\"\nScene 10: \"...\"\nScene 11: \"...\"\nScene 12: \"...\"\nScene 13: \"...\"\n\n"
        },
        "promptType": "define",
        "hasOutputParser": true
      },
      "typeVersion": 1.9
    },
    {
      "id": "4c34c0b0-5c13-4d37-8b51-a209e598513a",
      "name": "LLM: Draft Video Prompt Details (GPT-4.1)",
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenAi",
      "position": [
        1660,
        280
      ],
      "parameters": {
        "model": {
          "__rl": true,
          "mode": "list",
          "value": "gpt-4.1",
          "cachedResultName": "gpt-4.1"
        },
        "options": {}
      },
      "credentials": {
        "openAiApi": {
          "id": "6h3DfVhNPw9I25nO",
          "name": "OpenAi account"
        }
      },
      "typeVersion": 1.2
    },
    {
      "id": "5a7828fd-629c-45d4-9ff2-4b57be2eca33",
      "name": "Tool: Refine and Validate Prompts1",
      "type": "@n8n/n8n-nodes-langchain.toolThink",
      "position": [
        1840,
        280
      ],
      "parameters": {},
      "typeVersion": 1
    },
    {
      "id": "bddb974b-e541-4f02-8595-45f76820b38e",
      "name": "Parse Structured Video Prompt Output",
      "type": "@n8n/n8n-nodes-langchain.outputParserStructured",
      "position": [
        2000,
        280
      ],
      "parameters": {
        "jsonSchemaExample": "{\n  \"Idea\": \"An obsidian rock being sliced with a shimmering knife\",\n  \"Environment\": \"Clean studio table, subtle light reflections\",\n  \"Sound\": \"Crisp slicing, deep grinding, and delicate crumbling\",\n  \"Scene 1\": \"Extreme macro shot: a razor-sharp, polished knife blade presses into the dark, granular surface of an obsidian rock, just beginning to indent.\",\n  \"Scene 2\": \"Close-up: fine, iridescent dust particles erupt from the point of contact as the blade cuts deeper into the obsidian, catching the studio light.\",\n  \"Scene 3\": \"Mid-shot: the knife, held perfectly steady, has formed a shallow, clean groove across the obsidian's shimmering surface, revealing a new, smooth texture.\"\n}"
      },
      "typeVersion": 1.2
    },
    {
      "id": "443d3b99-1e6c-423c-b8ca-1c5a4c3ba180",
      "name": "Extract Individual Scene Descriptions",
      "type": "n8n-nodes-base.code",
      "position": [
        680,
        540
      ],
      "parameters": {
        "jsCode": "function findSceneEntries(obj) {\n  const scenes = [];\n\n  for (const [key, value] of Object.entries(obj)) {\n    if (key.toLowerCase().startsWith(\"scene\") && typeof value === \"string\") {\n      scenes.push(value);\n    } else if (typeof value === \"object\" && value !== null) {\n      scenes.push(...findSceneEntries(value));\n    }\n  }\n\n  return scenes;\n}\n\nlet output = [];\n\ntry {\n  const inputData = items[0].json;\n  const scenes = findSceneEntries(inputData);\n\n  if (scenes.length === 0) {\n    throw new Error(\"No scene keys found at any level.\");\n  }\n\n  output = scenes.map(scene => ({ description: scene }));\n} catch (e) {\n  throw new Error(\"Could not extract scenes properly. Details: \" + e.message);\n}\n\nreturn output;\n"
      },
      "typeVersion": 2
    },
    {
      "id": "78fc7648-9741-48c9-8127-2bdab7070ba7",
      "name": "Generate Video Clips (Wavespeed AI)",
      "type": "n8n-nodes-base.httpRequest",
      "position": [
        880,
        540
      ],
      "parameters": {
        "url": "https://api.wavespeed.ai/api/v3/bytedance/seedance-v1-pro-t2v-480p",
        "body": "={\n  \"aspect_ratio\": \"9:16\",\n  \"duration\": 10,\n  \"prompt\": \"VIDEO THEME: {{ $('Prompts AI Agent').item.json.output.Idea }} | WHAT HAPPENS IN THE VIDEO: {{ $json.description }} | WHERE THE VIDEO IS SHOT: {{ $('Prompts AI Agent').item.json.output.Environment }}\"\n}\n",
        "method": "POST",
        "options": {
          "batching": {
            "batch": {
              "batchSize": 1,
              "batchInterval": 3000
            }
          }
        },
        "sendBody": true,
        "contentType": "raw",
        "authentication": "genericCredentialType",
        "rawContentType": "application/json",
        "genericAuthType": "httpHeaderAuth"
      },
      "credentials": {
        "httpHeaderAuth": {
          "id": "QhpKhFJMiQAReugp",
          "name": "Header Auth account 4"
        }
      },
      "typeVersion": 4.2
    },
    {
      "id": "62eb02cb-cf85-4cbe-8688-8fd587e9c19a",
      "name": "Wait for Clip Generation (Wavespeed AI)",
      "type": "n8n-nodes-base.wait",
      "position": [
        1080,
        540
      ],
      "webhookId": "60604cd4-5d90-48dc-93f4-1335e5f03fdd",
      "parameters": {
        "amount": 240
      },
      "typeVersion": 1.1
    },
    {
      "id": "879f74ba-0e59-43a1-b949-c23bfbcceef0",
      "name": "Retrieve Video Clips",
      "type": "n8n-nodes-base.httpRequest",
      "position": [
        1280,
        540
      ],
      "parameters": {
        "url": "=https://api.wavespeed.ai/api/v3/predictions/{{ $json.data.id }}/result",
        "options": {},
        "authentication": "genericCredentialType",
        "genericAuthType": "httpHeaderAuth"
      },
      "credentials": {
        "httpHeaderAuth": {
          "id": "QhpKhFJMiQAReugp",
          "name": "Header Auth account 4"
        }
      },
      "typeVersion": 4.2
    },
    {
      "id": "1bc37dc5-fd16-4dc0-a153-11d19d8d4068",
      "name": "Generate ASMR Sound (Fal AI)",
      "type": "n8n-nodes-base.httpRequest",
      "position": [
        1560,
        540
      ],
      "parameters": {
        "url": "https://queue.fal.run/fal-ai/mmaudio-v2 ",
        "body": "= {\n        \"prompt\": \"ASMR Soothing sound effects. {{ $('AI Agent: Generate Detailed Video Prompts').item.json.output.Sound }}\",\n        \"duration\": 10,\n        \"video_url\": \"{{ $json.data.outputs[0] }}\"\n  }\n",
        "method": "POST",
        "options": {
          "batching": {
            "batch": {
              "batchSize": 1,
              "batchInterval": 2000
            }
          }
        },
        "sendBody": true,
        "contentType": "raw",
        "authentication": "genericCredentialType",
        "rawContentType": "application/json",
        "genericAuthType": "httpHeaderAuth"
      },
      "credentials": {
        "httpHeaderAuth": {
          "id": "QhpKhFJMiQAReugp",
          "name": "Header Auth account 4"
        }
      },
      "typeVersion": 4.2
    },
    {
      "id": "f8f1eae5-a74b-49be-81fd-2d13e75441c7",
      "name": "Wait for Sound Generation (Fal AI)",
      "type": "n8n-nodes-base.wait",
      "position": [
        1760,
        540
      ],
      "webhookId": "abac7859-a9f6-46f3-95c2-df43ec32807d",
      "parameters": {
        "amount": 60
      },
      "typeVersion": 1.1
    },
    {
      "id": "4670c2d4-0d66-42e9-891f-1f80508433bb",
      "name": "Retrieve Final Sound Output",
      "type": "n8n-nodes-base.httpRequest",
      "position": [
        1960,
        540
      ],
      "parameters": {
        
